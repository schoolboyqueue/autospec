feature:
    branch: "043-workflow-mock-coverage"
    created: "2025-12-18"
    status: "Completed"
    completed_at: 2025-12-18T04:29:11Z
    input: |
        Workflow Package Mock Coverage Enhancement - Reach 85% test coverage for internal/workflow/ (currently at 79.4%).

        Key Finding: Existing tests don't call target functions. Tests TestExecuteSinglePhaseSession and
        TestExecuteSingleTaskSession only test string formatting - they never actually call the methods.

        Mock infrastructure available: mock-claude.sh (simulates Claude CLI), MockClaudeExecutor (Go-level mock),
        newTestOrchestratorWithSpecName() helper. Functions with 0% coverage: PromptUserToContinue,
        runPreflightChecks, executeAndVerifyTask, executeSingleTaskSession. Functions with <60% coverage:
        startProgressDisplay, executeSinglePhaseSession, completeStageSuccessNoNotify, executeTaskLoop,
        CleanupContextFile.

        Implementation phases: Phase 1 (Quick Wins) - write tests that actually call functions using existing
        mock infrastructure. Phase 2 (Minor Refactoring) - stdin/preflight mocking via interface injection.
        Phase 3 (Edge Cases) - error path coverage.
user_stories:
    - id: "US-001"
      title: "Achieve 85% test coverage in workflow package"
      priority: "P1"
      as_a: "developer maintaining the autospec codebase"
      i_want: "the internal/workflow package to have at least 85% test coverage"
      so_that: "I can confidently refactor and extend workflow functionality without introducing regressions"
      why_this_priority: "Test coverage is foundational for code quality; the gap from 79.4% to 85% represents untested critical paths"
      independent_test: "Run 'go test -cover ./internal/workflow/' and verify coverage >= 85%"
      acceptance_scenarios:
        - given: "the internal/workflow package exists with current 79.4% coverage"
          when: "I run 'go test -cover ./internal/workflow/'"
          then: "coverage output shows >= 85.0%"
    - id: "US-002"
      title: "Integration tests call actual workflow methods"
      priority: "P1"
      as_a: "developer writing tests for workflow functions"
      i_want: "integration tests that actually invoke the methods under test"
      so_that: "the tests validate real behavior rather than just string formatting"
      why_this_priority: "Current tests are misleading - they pass but don't exercise the code paths they claim to test"
      independent_test: "Review test code to confirm actual method invocation; verify coverage increases for target functions"
      acceptance_scenarios:
        - given: "existing tests that only test string formatting (e.g., TestExecuteSingleTaskSession)"
          when: "tests are rewritten to call the actual methods using newTestOrchestratorWithSpecName()"
          then: "coverage for executeSingleTaskSession increases from 0% to > 80%"
    - id: "US-003"
      title: "Mock infrastructure supports stdin input testing"
      priority: "P2"
      as_a: "developer testing user prompt functions"
      i_want: "the ability to mock stdin input in tests"
      so_that: "I can test PromptUserToContinue without requiring manual input"
      why_this_priority: "PromptUserToContinue has 0% coverage due to stdin dependency; testable via simple refactoring"
      independent_test: "Run tests for PromptUserToContinue variants and verify coverage > 0%"
      acceptance_scenarios:
        - given: "PromptUserToContinue reads from os.Stdin directly"
          when: "a new variant PromptUserToContinueWithReader(reader io.Reader) is added"
          then: "tests can inject mock readers and achieve > 80% coverage for the function"
    - id: "US-004"
      title: "Preflight checks are testable via dependency injection"
      priority: "P2"
      as_a: "developer testing workflow initialization"
      i_want: "runPreflightChecks to be testable without real system dependencies"
      so_that: "I can test preflight check scenarios (pass, warn, fail) in isolation"
      why_this_priority: "runPreflightChecks has 0% coverage; interface injection enables comprehensive testing"
      independent_test: "Run tests with MockPreflightChecker and verify coverage increases"
      acceptance_scenarios:
        - given: "runPreflightChecks calls real system check functions"
          when: "a PreflightChecker interface is injected into WorkflowOrchestrator"
          then: "tests can use MockPreflightChecker to simulate all check outcomes"
requirements:
    functional:
        - id: "FR-001"
          description: "MUST add integration tests for executeSingleTaskSession that invoke the actual method"
          testable: true
          acceptance_criteria: "Test function creates orchestrator, sets up artifacts, calls executeSingleTaskSession, verifies task completion"
        - id: "FR-002"
          description: "MUST add integration tests for executeSinglePhaseSession that invoke the actual method"
          testable: true
          acceptance_criteria: "Test function creates orchestrator, sets up phase artifacts, calls executeSinglePhaseSession, verifies execution"
        - id: "FR-003"
          description: "MUST add integration tests for executeAndVerifyTask that invoke the actual method"
          testable: true
          acceptance_criteria: "Test function loads task from tasks.yaml, calls executeAndVerifyTask, verifies task state change"
        - id: "FR-004"
          description: "MUST add integration tests for executeTaskLoop that invoke the actual method"
          testable: true
          acceptance_criteria: "Test function sets up task list with mixed states, calls executeTaskLoop, verifies only pending tasks executed"
        - id: "FR-005"
          description: "SHOULD add PromptUserToContinueWithReader variant accepting io.Reader parameter"
          testable: true
          acceptance_criteria: "New function exists, original function delegates to it with os.Stdin, tests cover y/n/yes/no/empty inputs"
        - id: "FR-006"
          description: "SHOULD create PreflightChecker interface for dependency injection"
          testable: true
          acceptance_criteria: "Interface defined, WorkflowOrchestrator accepts it, mock implementation exists"
        - id: "FR-007"
          description: "MAY add edge case tests for startProgressDisplay, completeStageSuccessNoNotify, CleanupContextFile"
          testable: true
          acceptance_criteria: "Tests cover nil checks, error paths, and file-not-found scenarios"
        - id: "FR-008"
          description: "MUST pass all quality gates: make test, make fmt, make lint, and make build"
          testable: true
          acceptance_criteria: "All commands exit 0; no test failures, format changes, lint errors, or build failures"
    non_functional:
        - id: "NFR-001"
          category: "code_quality"
          description: "All functions must be under 40 lines; extract helpers for complex logic"
          measurable_target: "No function exceeds 40 lines excluding comments"
        - id: "NFR-002"
          category: "code_quality"
          description: "All errors must be wrapped with context using fmt.Errorf(\"doing X: %w\", err)"
          measurable_target: "Zero bare 'return err' statements in new code"
        - id: "NFR-003"
          category: "code_quality"
          description: "Tests must use map-based table-driven pattern with t.Parallel() where applicable"
          measurable_target: "All new test functions use map[string]struct pattern; t.Parallel() used except where env vars require sequential execution"
        - id: "NFR-004"
          category: "code_quality"
          description: "Accept interfaces, return concrete types"
          measurable_target: "Function signatures follow interface-in, concrete-out pattern where applicable"
        - id: "NFR-005"
          category: "reliability"
          description: "No breaking changes to existing public API"
          measurable_target: "All existing tests pass without modification to test assertions"
        - id: "NFR-006"
          category: "performance"
          description: "New tests must complete within reasonable time"
          measurable_target: "Individual test functions complete in under 5 seconds"
success_criteria:
    measurable_outcomes:
        - id: "SC-001"
          description: "Package test coverage reaches target threshold"
          metric: "go test -cover ./internal/workflow/ output"
          target: ">= 85.0% coverage"
        - id: "SC-002"
          description: "Previously uncovered functions now have meaningful coverage"
          metric: "Coverage per function for executeSingleTaskSession, executeSinglePhaseSession, executeAndVerifyTask, executeTaskLoop"
          target: "> 60% coverage for each function"
        - id: "SC-003"
          description: "All quality gates pass"
          metric: "Exit codes from make test, make fmt, make lint, make build"
          target: "All commands return exit code 0"
        - id: "SC-004"
          description: "No test flakiness introduced"
          metric: "Run test suite 3 times consecutively"
          target: "All runs pass (100% consistency)"
key_entities:
    - name: "WorkflowOrchestrator"
      description: "Main orchestrator coordinating workflow execution stages"
      attributes:
        - "Executor (handles Claude CLI invocation)"
        - "Config (workflow configuration)"
        - "PreflightChecker (optional, for dependency injection)"
    - name: "MockClaudeExecutor"
      description: "Go-level mock for testing without subprocess calls"
      attributes:
        - "ExecuteStageFunc (customizable behavior)"
        - "Call recording for verification"
    - name: "mock-claude.sh"
      description: "Shell script simulating Claude CLI for integration tests"
      attributes:
        - "MOCK_ARTIFACT_DIR (triggers artifact generation)"
        - "MOCK_EXIT_CODE (configurable exit status)"
        - "MOCK_CALL_LOG (records invocations)"
    - name: "PreflightChecker"
      description: "Interface for preflight system dependency injection"
      attributes:
        - "RunPreflightChecks() method"
        - "PromptUserToContinue() method"
edge_cases:
    - scenario: "executeTaskLoop called with empty task list"
      expected_behavior: "Returns nil immediately without executing anything"
    - scenario: "executeTaskLoop called with all tasks already completed"
      expected_behavior: "Skips all tasks, returns nil"
    - scenario: "executeSinglePhaseSession called with phase containing no pending tasks"
      expected_behavior: "Skips execution, returns nil"
    - scenario: "executeAndVerifyTask called with task that has unmet dependencies"
      expected_behavior: "Skips task with informational message, returns nil"
    - scenario: "PromptUserToContinue receives EOF from reader"
      expected_behavior: "Returns (false, nil) - treats EOF as declining to continue"
    - scenario: "PromptUserToContinue receives read error"
      expected_behavior: "Returns (false, error) with wrapped error context"
    - scenario: "CleanupContextFile called with non-existent file"
      expected_behavior: "Returns nil (cleanup is idempotent)"
    - scenario: "startProgressDisplay called with nil ProgressDisplay"
      expected_behavior: "No panic, gracefully skips progress display"
assumptions:
    - "mock-claude.sh correctly simulates Claude CLI behavior for artifact generation"
    - "newTestOrchestratorWithSpecName() properly configures the test environment"
    - "Existing mock infrastructure (MockClaudeExecutor) is stable and well-tested"
    - "t.Setenv() prevents t.Parallel() usage in integration tests (per Go testing semantics)"
    - "The validation package (validation.GetAllTasks, etc.) functions correctly"
constraints:
    - "Cannot use t.Parallel() in tests that use t.Setenv() for mock-claude.sh configuration"
    - "Must not modify public API signatures in ways that break existing consumers"
    - "Must maintain backward compatibility with existing test patterns"
    - "Interface injection must be optional (nil-safe) to avoid breaking existing code"
out_of_scope:
    - "Achieving 100% test coverage (target is 85%)"
    - "Refactoring workflow logic beyond what's needed for testability"
    - "Adding new workflow features or stages"
    - "Performance optimization of existing workflow code"
    - "Testing external dependencies (actual Claude CLI, git operations)"
    - "Changes to mock-claude.sh script itself"
_meta:
    version: "1.0.0"
    generator: "autospec"
    generator_version: "autospec dev"
    created: "2025-12-18T03:59:54Z"
    artifact_type: "spec"
