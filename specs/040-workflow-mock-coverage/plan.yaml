plan:
  branch: "040-workflow-mock-coverage"
  created: "2025-12-18"
  spec_path: "specs/040-workflow-mock-coverage/spec.yaml"

summary: |
  This plan addresses the critical gap in workflow test coverage where Execute* methods have
  0% coverage despite existing test infrastructure. The root cause is that current tests
  interact with mock executors directly rather than injecting mocks into WorkflowOrchestrator
  to test actual workflow methods.

  The implementation will enhance the MockClaudeExecutor and MockExecutorBuilder to properly
  integrate with WorkflowOrchestrator, enabling tests to call real Execute* methods while
  using mock-claude.sh for artifact generation. This approach maintains test isolation via
  t.TempDir() while achieving 85-90% coverage on core workflow orchestration code.

technical_context:
  language: "Go"
  framework: "None"
  primary_dependencies:
    - name: "testing"
      version: "stdlib"
      purpose: "Go standard testing framework"
    - name: "gopkg.in/yaml.v3"
      version: "v3.0.1"
      purpose: "YAML parsing for artifact validation"
  storage: "File system (temp directories)"
  testing:
    framework: "Go testing package"
    approach: "Map-based table-driven tests with t.Parallel() where safe; mock executor injection; artifact generation via mock-claude.sh"
  target_platform: "Linux, macOS, Windows"
  project_type: "cli"
  performance_goals: "Test suite execution under 20 seconds; no flaky tests"
  constraints:
    - "Must not call real Claude CLI (API costs)"
    - "Must not modify repository git state"
    - "Each test uses isolated t.TempDir()"
    - "All resources cleaned up automatically"
  scale_scope: "Unit and integration tests for workflow package"

constitution_check:
  constitution_path: ".autospec/memory/constitution.yaml"
  gates:
    - name: "Test-First Development (PRIN-001)"
      status: "PASS"
      notes: "This spec is specifically about adding tests to achieve coverage targets"
    - name: "Validation-First Workflow (PRIN-002)"
      status: "PASS"
      notes: "Tests will validate artifact generation matches expected schemas"
    - name: "Performance Standards (PRIN-003)"
      status: "PASS"
      notes: "Target is test execution under 20 seconds; validation functions already meet <10ms"
    - name: "Go Coding Standards (PRIN-011)"
      status: "PASS"
      notes: "Tests will use map-based table-driven pattern; functions under 40 lines"

research_findings:
  decisions:
    - topic: "Mock injection strategy"
      decision: "Inject MockClaudeExecutor into WorkflowOrchestrator.Executor.Claude field"
      rationale: "WorkflowOrchestrator already exposes Executor which contains Claude interface; allows testing real orchestration logic"
      alternatives_considered:
        - "Create wrapper interface for WorkflowOrchestrator (too invasive)"
        - "Use dependency injection constructor (would break existing API)"
    - topic: "Artifact generation approach"
      decision: "Use mock-claude.sh script with MOCK_RESPONSE_FILE environment variable"
      rationale: "Script already exists and supports artifact file generation; integrates with existing ClaudeCmd config"
      alternatives_considered:
        - "In-memory artifact generation (doesn't test full path)"
        - "Generate artifacts in test setup (misses integration)"
    - topic: "Test isolation strategy"
      decision: "Use t.TempDir() for all file operations; avoid t.Parallel() for tests using GitIsolation"
      rationale: "t.TempDir() provides automatic cleanup; GitIsolation changes working directory which breaks parallel execution"
      alternatives_considered:
        - "Shared temp directories (race conditions)"
        - "Manual cleanup (error prone)"
    - topic: "Coverage target"
      decision: "Target 85% minimum with stretch goal of 90%"
      rationale: "50% to 85% is achievable by covering Execute* methods; 90% requires error path coverage"
      alternatives_considered:
        - "100% coverage (diminishing returns for internal details)"
        - "70% coverage (too low for critical workflow code)"

data_model:
  entities:
    - name: "MockExecutorBuilder"
      description: "Fluent builder for configuring mock executor behavior"
      fields:
        - name: "responses"
          type: "[]mockResponse"
          description: "Queue of responses to return"
          constraints: "Order preserved for sequential calls"
        - name: "artifactDir"
          type: "string"
          description: "Directory where artifacts will be generated"
          constraints: "Must exist when artifacts are generated"
        - name: "mockClaudePath"
          type: "string"
          description: "Path to mock-claude.sh script"
          constraints: "Must be executable"
      relationships:
        - target: "MockExecutor"
          type: "one-to-one"
          description: "Builder creates MockExecutor via Build()"
    - name: "WorkflowOrchestrator"
      description: "Main orchestration component being tested"
      fields:
        - name: "Executor"
          type: "*Executor"
          description: "Executor with injectable Claude implementation"
          constraints: "Claude field must implement ClaudeExecutorInterface"
        - name: "SpecsDir"
          type: "string"
          description: "Directory for spec artifacts"
          constraints: "Must be writable"
      relationships:
        - target: "Executor"
          type: "one-to-one"
          description: "Orchestrator uses Executor for stage execution"

api_contracts:
  endpoints: []

project_structure:
  documentation:
    - path: "docs/testing-mocks.md"
      description: "Existing documentation on mock testing patterns"
    - path: "mocks/README.md"
      description: "Mock infrastructure documentation"
  source_code:
    - path: "internal/workflow/workflow.go"
      description: "Main workflow orchestration (Execute* methods)"
    - path: "internal/workflow/executor.go"
      description: "Stage execution and retry logic"
    - path: "internal/testutil/mock_executor.go"
      description: "Mock executor builder and implementation"
    - path: "mocks/scripts/mock-claude.sh"
      description: "Shell script simulating Claude CLI"
  tests:
    - path: "internal/workflow/workflow_test.go"
      description: "Primary test file for workflow orchestration"
    - path: "internal/workflow/integration_test.go"
      description: "Integration tests with mock infrastructure"
    - path: "mocks/scripts/mock_claude_test.go"
      description: "Tests for mock-claude.sh behavior"

implementation_phases:
  - phase: 1
    name: "Mock Infrastructure Enhancement"
    goal: "Enable MockExecutor to integrate with WorkflowOrchestrator for testing Execute* methods"
    deliverables:
      - "Enhanced MockExecutorBuilder with artifact-generating callbacks"
      - "Helper functions to inject mock into WorkflowOrchestrator"
      - "Test fixtures for valid spec, plan, tasks artifacts"

  - phase: 2
    name: "Execute* Method Tests"
    goal: "Achieve coverage for all Execute* methods in workflow.go"
    dependencies:
      - "Phase 1"
    deliverables:
      - "Tests for ExecuteSpecify with artifact validation"
      - "Tests for ExecutePlan with artifact validation"
      - "Tests for ExecuteTasks with artifact validation"
      - "Tests for ExecuteImplement (basic coverage)"
      - "Tests for auxiliary Execute* methods (Constitution, Clarify, Checklist, Analyze)"

  - phase: 3
    name: "Workflow Integration Tests"
    goal: "Cover RunCompleteWorkflow and RunFullWorkflow end-to-end"
    dependencies:
      - "Phase 2"
    deliverables:
      - "Test for RunCompleteWorkflow with sequential mock responses"
      - "Test for RunFullWorkflow with implementation stage"
      - "Tests for error handling and retry behavior"

  - phase: 4
    name: "Error Path Coverage"
    goal: "Increase coverage with error handling tests"
    dependencies:
      - "Phase 3"
    deliverables:
      - "Tests for validation failures at each stage"
      - "Tests for retry exhaustion scenarios"
      - "Tests for preflight check failures"

risks:
  - risk: "GitIsolation tests cannot run in parallel"
    likelihood: "high"
    impact: "low"
    mitigation: "Clearly document with comments; use t.Parallel() only for isolated tests"
  - risk: "Mock artifact generation may not match real Claude output"
    likelihood: "medium"
    impact: "medium"
    mitigation: "Validate generated artifacts with autospec artifact command"
  - risk: "Test execution time increases significantly"
    likelihood: "low"
    impact: "medium"
    mitigation: "Target <20s total; use parallel execution where safe"

open_questions:
  - question: "Should ExecuteImplementWithTasks and ExecuteImplementWithPhases have separate test files?"
    context: "These methods have complex task-by-task iteration logic"
    proposed_resolution: "Keep in workflow_test.go but use separate test functions with clear naming"
  - question: "How to test timeout behavior without slowing down test suite?"
    context: "MOCK_DELAY environment variable can simulate timeouts"
    proposed_resolution: "Use short delays (50ms) with tight timeouts (25ms) for timeout tests only"

_meta:
  version: "1.0.0"
  generator: "autospec"
  generator_version: "autospec dev"
  created: "2025-12-18T02:53:23Z"
  artifact_type: "plan"
